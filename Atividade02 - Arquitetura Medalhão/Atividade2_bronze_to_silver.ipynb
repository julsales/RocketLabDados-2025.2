{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a454e8c-d045-4989-8025-e7ebffac4549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "# garante que os bancos existem\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS bronze\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS silver\")\n",
    "spark.catalog.setCurrentDatabase(\"silver\")\n",
    "\n",
    "# ft_consumidores\n",
    "df = spark.table(\"bronze.ft_consumidores\").dropDuplicates([\"customer_id\"])\n",
    "df = (df\n",
    "    .filter(F.col(\"customer_id\").isNotNull())\n",
    "    .withColumnRenamed(\"customer_id\", \"id_consumidor\")\n",
    "    .withColumnRenamed(\"customer_zip_code_prefix\", \"prefixo_cep\")\n",
    "    .withColumnRenamed(\"customer_city\", \"cidade\")\n",
    "    .withColumnRenamed(\"customer_state\", \"estado\")\n",
    "    .withColumn(\"cidade\", F.upper(\"cidade\"))\n",
    "    .withColumn(\"estado\", F.upper(\"estado\")))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.ft_consumidores\")\n",
    "\n",
    "# ft_pedidos\n",
    "status_map = {\n",
    "    \"delivered\": \"entregue\", \"invoiced\": \"faturado\", \"shipped\": \"enviado\",\n",
    "    \"processing\": \"em processamento\", \"unavailable\": \"indisponível\",\n",
    "    \"canceled\": \"cancelado\", \"created\": \"criado\", \"approved\": \"aprovado\"\n",
    "}\n",
    "map_expr = F.create_map(*[F.lit(i) for kv in status_map.items() for i in kv])\n",
    "\n",
    "df = spark.table(\"bronze.ft_pedidos\")\n",
    "df = (df\n",
    "    .filter(F.col(\"order_purchase_timestamp\").isNotNull())\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "    .withColumnRenamed(\"order_id\",\"id_pedido\")\n",
    "    .withColumnRenamed(\"customer_id\",\"id_consumidor\")\n",
    "    .withColumnRenamed(\"order_purchase_timestamp\",\"pedido_compra_timestamp\")\n",
    "    .withColumnRenamed(\"order_approved_at\",\"pedido_aprovado_timestamp\")\n",
    "    .withColumnRenamed(\"order_delivered_carrier_date\",\"pedido_carregado_timestamp\")\n",
    "    .withColumnRenamed(\"order_delivered_customer_date\",\"pedido_entregue_timestamp\")\n",
    "    .withColumnRenamed(\"order_estimated_delivery_date\",\"pedido_estimativa_entrega_timestamp\")\n",
    "    .withColumn(\"status\", F.coalesce(map_expr[F.col(\"order_status\")], F.lit(\"desconhecido\")))\n",
    "    .withColumn(\"pedido_compra_timestamp\", F.try_to_timestamp(\"pedido_compra_timestamp\"))\n",
    "    .withColumn(\"pedido_aprovado_timestamp\", F.try_to_timestamp(\"pedido_aprovado_timestamp\"))\n",
    "    .withColumn(\"pedido_carregado_timestamp\", F.try_to_timestamp(\"pedido_carregado_timestamp\"))\n",
    "    .withColumn(\"pedido_entregue_timestamp\", F.try_to_timestamp(\"pedido_entregue_timestamp\"))\n",
    "    .withColumn(\"pedido_estimativa_entrega_timestamp\", F.try_to_timestamp(\"pedido_estimativa_entrega_timestamp\"))\n",
    "    .withColumn(\"tempo_entrega_dias\", F.datediff(\"pedido_entregue_timestamp\",\"pedido_compra_timestamp\"))\n",
    "    .withColumn(\"tempo_entrega_estimado_dias\", F.datediff(\"pedido_estimativa_entrega_timestamp\",\"pedido_compra_timestamp\"))\n",
    "    .withColumn(\"diferenca_entrega_dias\", F.col(\"tempo_entrega_estimado_dias\") - F.col(\"tempo_entrega_dias\"))\n",
    "    .withColumn(\"entrega_no_prazo\",\n",
    "        F.when(F.col(\"pedido_entregue_timestamp\").isNull(),\"Não Entregue\")\n",
    "         .when(F.col(\"diferenca_entrega_dias\") >= 0,\"Sim\")\n",
    "         .otherwise(\"Não\"))\n",
    ")\n",
    "df = df.filter(F.col(\"id_consumidor\").isNotNull())\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.ft_pedidos\")\n",
    "\n",
    "# ft_itens_pedidos\n",
    "df = spark.table(\"bronze.ft_itens_pedidos\")\n",
    "df = (df\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "    .withColumnRenamed(\"order_id\",\"id_pedido\")\n",
    "    .withColumnRenamed(\"order_item_id\",\"id_item\")\n",
    "    .withColumnRenamed(\"product_id\",\"id_produto\")\n",
    "    .withColumnRenamed(\"seller_id\",\"id_vendedor\")\n",
    "    .withColumnRenamed(\"price\",\"preco_BRL\")\n",
    "    .withColumnRenamed(\"freight_value\",\"preco_frete\")\n",
    "    .withColumn(\"preco_BRL\", F.col(\"preco_BRL\").cast(\"decimal(12,2)\"))\n",
    "    .withColumn(\"preco_frete\", F.col(\"preco_frete\").cast(\"decimal(12,2)\")))\n",
    "df = df.dropna(subset=[\"id_pedido\",\"id_item\",\"id_produto\"])\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.ft_itens_pedidos\")\n",
    "\n",
    "# ft_pagamentos\n",
    "map_pag = {\n",
    "    \"credit_card\": \"Cartão de Crédito\",\n",
    "    \"boleto\": \"Boleto\",\n",
    "    \"voucher\": \"Voucher\",\n",
    "    \"debit_card\": \"Cartão de Débito\"\n",
    "}\n",
    "map_expr = F.create_map(*[F.lit(i) for kv in map_pag.items() for i in kv])\n",
    "\n",
    "df = spark.table(\"bronze.ft_pagamentos_pedidos\")\n",
    "df = (df\n",
    "    .filter(F.col(\"order_id\").isNotNull())\n",
    "    .withColumnRenamed(\"order_id\",\"id_pedido\")\n",
    "    .withColumnRenamed(\"payment_sequential\",\"codigo_pagamento\")\n",
    "    .withColumnRenamed(\"payment_type\",\"forma_pagamento\")\n",
    "    .withColumnRenamed(\"payment_installments\",\"parcelas\")\n",
    "    .withColumnRenamed(\"payment_value\",\"valor_pagamento\")\n",
    "    .withColumn(\"forma_pagamento\", F.coalesce(map_expr[F.col(\"forma_pagamento\")], F.lit(\"Outro\")))\n",
    "    .withColumn(\"valor_pagamento\", F.col(\"valor_pagamento\").cast(\"decimal(12,2)\")))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.ft_pagamentos\")\n",
    "\n",
    "# ft_avaliacoes_pedidos\n",
    "df = spark.table(\"bronze.ft_avaliacoes_pedidos\")\n",
    "ped = spark.table(\"bronze.ft_pedidos\").select(\"order_id\")\n",
    "df = (df\n",
    "    .filter(F.col(\"review_id\").isNotNull())\n",
    "    .withColumn(\"review_creation_date\", F.try_to_timestamp(\"review_creation_date\"))\n",
    "    .withColumn(\"review_answer_timestamp\", F.try_to_timestamp(\"review_answer_timestamp\"))\n",
    "    .filter(F.col(\"review_creation_date\").isNotNull())\n",
    "    .join(ped, \"order_id\", \"inner\")\n",
    "    .withColumnRenamed(\"review_id\",\"id_avaliacao\")\n",
    "    .withColumnRenamed(\"order_id\",\"id_pedido\")\n",
    "    .withColumnRenamed(\"review_score\",\"avaliacao\")\n",
    "    .withColumnRenamed(\"review_comment_title\",\"titulo_comentario\")\n",
    "    .withColumnRenamed(\"review_comment_message\",\"comentario\")\n",
    "    .withColumnRenamed(\"review_creation_date\",\"data_comentario\")\n",
    "    .withColumnRenamed(\"review_answer_timestamp\",\"data_resposta\"))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.ft_avaliacoes_pedidos\")\n",
    "\n",
    "# ft_produtos\n",
    "df = spark.table(\"bronze.ft_produtos\")\n",
    "df = (df\n",
    "    .filter(F.col(\"product_id\").isNotNull())\n",
    "    .withColumnRenamed(\"product_id\",\"id_produto\")\n",
    "    .withColumnRenamed(\"product_category_name\",\"categoria_produto\")\n",
    "    .withColumnRenamed(\"product_weight_g\",\"peso_produto_gramas\")\n",
    "    .withColumnRenamed(\"product_length_cm\",\"comprimento_centimetros\")\n",
    "    .withColumnRenamed(\"product_height_cm\",\"altura_centimetros\")\n",
    "    .withColumnRenamed(\"product_width_cm\",\"largura_centimetros\"))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.ft_produtos\")\n",
    "\n",
    "# ft_vendedores\n",
    "df = spark.table(\"bronze.ft_vendedores\")\n",
    "df = (df\n",
    "    .filter(F.col(\"seller_id\").isNotNull())\n",
    "    .withColumnRenamed(\"seller_id\",\"id_vendedor\")\n",
    "    .withColumnRenamed(\"seller_zip_code_prefix\",\"prefixo_cep\")\n",
    "    .withColumnRenamed(\"seller_city\",\"cidade\")\n",
    "    .withColumnRenamed(\"seller_state\",\"estado\")\n",
    "    .withColumn(\"cidade\", F.upper(\"cidade\"))\n",
    "    .withColumn(\"estado\", F.upper(\"estado\")))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.ft_vendedores\")\n",
    "\n",
    "# dm_categoria_produtos_traducao\n",
    "df = spark.table(\"bronze.dm_categoria_produtos_traducao\")\n",
    "df = (df\n",
    "    .filter(F.col(\"product_category_name\").isNotNull())\n",
    "    .withColumnRenamed(\"product_category_name\",\"nome_produto_pt\")\n",
    "    .withColumnRenamed(\"product_category_name_english\",\"nome_produto_en\"))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.dm_categoria_produtos_traducao\")\n",
    "\n",
    "# dm_cotacao_dolar\n",
    "df = spark.table(\"bronze.dm_cotacao_dolar\").select(\"dataHoraCotacao\",\"cotacaoCompra\")\n",
    "df = (df\n",
    "    .withColumn(\"data\", F.to_date(\"dataHoraCotacao\"))\n",
    "    .withColumn(\"cotacao_dolar\", F.col(\"cotacaoCompra\").cast(\"decimal(12,6)\"))\n",
    "    .select(\"data\",\"cotacao_dolar\").distinct().orderBy(\"data\"))\n",
    "min_date, max_date = df.agg(F.min(\"data\"), F.max(\"data\")).first()\n",
    "cal = (spark.createDataFrame([(min_date, max_date)], [\"start\",\"end\"])\n",
    "    .select(F.explode(F.expr(\"sequence(start, end, interval 1 day)\")).alias(\"data\")))\n",
    "df = (cal.join(df, \"data\", \"left\")\n",
    "    .withColumn(\"cotacao_dolar\", F.last(\"cotacao_dolar\", True).over(\n",
    "        Window.orderBy(\"data\").rowsBetween(Window.unboundedPreceding, 0))))\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"silver.dm_cotacao_dolar\")\n",
    "\n",
    "# integridade referencial\n",
    "ped = spark.table(\"silver.ft_pedidos\").select(\"id_pedido\",\"id_consumidor\")\n",
    "cons = spark.table(\"silver.ft_consumidores\").select(\"id_consumidor\")\n",
    "itens = spark.table(\"silver.ft_itens_pedidos\").select(\"id_pedido\")\n",
    "\n",
    "ped = ped.join(cons, \"id_consumidor\", \"inner\")\n",
    "itens = itens.join(ped.select(\"id_pedido\"), \"id_pedido\", \"inner\")\n",
    "\n",
    "ped.write.mode(\"overwrite\").saveAsTable(\"silver.ft_pedidos\")\n",
    "itens.write.mode(\"overwrite\").saveAsTable(\"silver.ft_itens_pedidos\")\n",
    "\n",
    "# ft_pedido_total\n",
    "ped = spark.table(\"silver.ft_pedidos\").alias(\"ped\").select(\n",
    "    \"id_pedido\", \"id_consumidor\", \"status\", \"pedido_compra_timestamp\"\n",
    ")\n",
    "pag = (spark.table(\"silver.ft_pagamentos\")\n",
    "    .groupBy(\"id_pedido\")\n",
    "    .agg(F.sum(\"valor_pagamento\").alias(\"valor_total_pago_brl\"))\n",
    ")\n",
    "cot = spark.table(\"silver.dm_cotacao_dolar\").alias(\"cot\")\n",
    "\n",
    "final = (ped\n",
    "    .withColumn(\"data_pedido\", F.to_date(F.col(\"pedido_compra_timestamp\")))\n",
    "    .join(pag, \"id_pedido\", \"left\")\n",
    "    .join(cot, F.col(\"ped.pedido_compra_timestamp\") >= F.col(\"cot.data\"), \"left\")\n",
    "    .withColumn(\"cotacao_dia\",\n",
    "        F.last(\"cot.cotacao_dolar\", True).over(\n",
    "            Window.partitionBy(\"ped.id_pedido\").orderBy(\"cot.data\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"valor_total_pago_usd\",\n",
    "        F.when(\n",
    "            F.col(\"valor_total_pago_brl\").isNotNull() & F.col(\"cotacao_dia\").isNotNull(),\n",
    "            F.round(F.col(\"valor_total_pago_brl\") / F.col(\"cotacao_dia\"), 2)\n",
    "        ).otherwise(None)\n",
    "    )\n",
    "    .select(\n",
    "        F.col(\"data_pedido\"),\n",
    "        F.col(\"ped.id_pedido\").alias(\"id_pedido\"),\n",
    "        F.col(\"ped.id_consumidor\").alias(\"id_consumidor\"),\n",
    "        F.col(\"ped.status\").alias(\"status\"),\n",
    "        F.col(\"valor_total_pago_brl\"),\n",
    "        F.col(\"valor_total_pago_usd\")\n",
    "    )\n",
    ")\n",
    "final.write.mode(\"overwrite\").saveAsTable(\"silver.ft_pedido_total\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Atividade2_bronze_to_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
